########################################################################################################################
# Copyright 2024 the authors (see AUTHORS file for full list).                                                         #
#                                                                                                                      #
#                                                                                                                      #
# This file is part of OpenCCM.                                                                                        #
#                                                                                                                      #
#                                                                                                                      #
# OpenCCM is free software: you can redistribute it and/or modify it under the terms of the GNU Lesser General Public  #
# License as published by the Free Software Foundation,either version 2.1 of the License, or (at your option)          #
# any later version.                                                                                                   #
#                                                                                                                      #
# OpenCCM is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied        #
# warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.                                                     #
# See the GNU Lesser General Public License for more details.                                                          #
#                                                                                                                      #
# You should have received a copy of the GNU Lesser General Public License along with OpenCCM. If not, see             #
# <https://www.gnu.org/licenses/>.                                                                                     #
########################################################################################################################

r"""
Functions related to parsing the boundary and initial conditions and then generating numba compiled code of the results
and applying them to the system.
"""

from scipy.spatial import KDTree
from typing import List, Tuple, Dict, Callable, Set, Optional
from collections import defaultdict

import numpy as np
import sympy as sp

from sympy.abc import x, y, z, t

from ..config_functions import ConfigParser
from ..mesh import CMesh, GroupedBCs
from .helper_functions import H

BC_TEMPLATE = "@njit(inline='always', cache=True)\n" + \
              "def {}(t):\n" + \
              "    return {}\n"
"""Template for generating the boudnary condition file."""
SYMPY_EQN_ARGS = [x, y, z, t]
"""TODO"""


def create_boundary_conditions(c0:                  np.ndarray,
                               config_parser:       ConfigParser,
                               Q_weights:           Dict[int, List[float]],
                               points_for_bc:       Dict[int, List[int]],
                               t0:                  float,
                               points_per_model:    int,
                               cmesh:               CMesh,
                               dof_to_element_map:  List[List[Tuple[int, int, float]]],
                               model_volumes:       np.ndarray) -> None:
    """
    CSTRs need the boundary condition in their original form since the equation for the inlets is sum (Q_in * C_in).
    PFRs however need the boundary condition in derivative form since the inlets to the PFRs produce a system of
    dynamic algebraic equations (DAEs).
    The need for a DEA solver is avoided by taking the derivative of that boundary condition but this in turn
    requires that the boundary condition be differentiated.

    If `need_time_deriv_version` is `true`, the boundary conditions generated by this function will be the time derivative version.

    This function also modifies c0 to apply the initial values of the boundary conditions to the whole domain.

    Limitations: (If any are exceeded, this function will throw an error.)
    - The boundary condition cannot be a function of spatial position along the boundary.
      Currently, only uniform values (which can be time-varying) are supported.
    - The boundary condition must be differentiable in time.

    Parameters
    ----------
    * c0:               The initial condition, needed in order to properly implement boundary conditions for PFR models.
                        The BC will override the IC value for the BC nodes.
    * config_parser:    OpenCCM ConfigParser for getting settings.
    * Q_weights:        Mapping between BC ID and a list of weights
                        The entries for each boundary condition MUST be in the same order as points_for_bc.
    * points_for_bc:    Mapping between boundary ID and the index into the state array.
                        Entries for each BC MUST be in the same order as Q_weights.
    * t0:               The starting time, needed for updating c0 if using a PFR model.
    * points_per_model: Number of discretization points per model. A value of 1 is assumed to represent a CSTR.
    * cmesh:
    * dof_to_element_map:
    * model_volumes:        TODO
    """
    def get_bc_id(_bc_name: str) -> int:
        if 'point' in _bc_name:
            return hash(_bc_name)
        else:
            return cmesh.grouped_bcs.id(_bc_name)

    points_for_bc = points_for_bc.copy()
    Q_weights     = Q_weights.copy()
    specie_names = config_parser.get_list(['SIMULATION', 'specie_names'], str)
    assert len(specie_names) == c0.shape[0]

    # CSTR models will only have one discretization points per model. PFRs must have at least two (inlet and outlet).
    need_time_deriv_version = points_per_model > 1

    # Internal dict used to ensure that no variable is specified multiple times for each BC.
    anti_duplicate_dict: Dict[int, List[str]] = defaultdict(list)

    # List of lines to print for the boundary conditions file
    bc_file_lines: List[str] = [
        "from math import *\n",
        "from numba import njit\n",
        "from numpy import array, ndarray\n",
        "\n"
        "import numpy as np"
        "\n",
        "\n",
    ]

    spatial_coords  = {x, y, z}
    bc_dict         = defaultdict(dict)  # For writing to file
    bc_dict_for_c0  = defaultdict(dict)  # For calculating new c0 values if using a PFR
    bcs_names_used  = set()

    bc_str = config_parser.get_item(['SIMULATION', 'boundary_conditions'], str)

    if 'point' in bc_str:
        # Only mapping a subset of elements: Those which have been compartmentalized AND those that DO NOT correspond
        # to a PFR's inlet DOF. The inlet DOF would be very complicated to set properly as it requires setting the
        # connected outlet DOFs to a value that satisfies the algebraic constraint
        num_elements = sum(len(mapping) for dof, mapping in enumerate(dof_to_element_map) if not dof_is_pfr_inlet(dof, points_per_model))
        dimensions = cmesh.element_centroids.shape[1]
        points_subset = np.zeros((num_elements, dimensions))
        subset_index_to_dof = np.empty(num_elements, dtype=np.min_scalar_type(len(dof_to_element_map)))
        index = 0
        for dof, mapping in enumerate(dof_to_element_map):
            if dof_is_pfr_inlet(dof, points_per_model):  # Skip inlet DOFs for PFRs
                continue
            for element, _, _ in mapping:
                subset_index_to_dof[index] = dof
                points_subset[index] = cmesh.element_centroids[element]
                index += 1
        tree = KDTree(points_subset)

        def nearest_dof_for_point(position) -> int:
            return subset_index_to_dof[tree.query(position)[1]]

    for bc_line in bc_str.splitlines():
        specie, bc_info = [item.strip() for item in bc_line.split(':')]
        if specie not in specie_names:
            raise ValueError(f'Unknown specie: {specie} when specifying boundary condition: {bc_line}.')

        bc_name, bc_eqn_str = [item.strip() for item in bc_info.split('->')]
        bc_is_point_ic = 'point' in bc_name
        if bc_name in cmesh.grouped_bcs.no_flux_names:
            raise ValueError(f'BC value specified for the no-flux bc {bc_name}.')

        bc_name_cleaned = bc_name
        for char_to_remove in '().,':
            bc_name_cleaned = bc_name_cleaned.replace(char_to_remove, '_')

        bcs_names_used.add(bc_name_cleaned)
        bc_id = get_bc_id(bc_name_cleaned)
        if not bc_is_point_ic:
            if specie in anti_duplicate_dict[bc_id]:
                raise ValueError(f"Specie {specie} has multiple BCs specified for boundary {bc_name}.")
            else:
                anti_duplicate_dict[bc_id].append(specie)

        if bc_is_point_ic:
            dof   = nearest_dof_for_point(eval(bc_name.replace('point', '')))
            model = int(dof / points_per_model)
            dofs_for_bc = [model] if points_per_model == 1 else list(range(model*points_per_model+1, (model+1)*points_per_model))
            points_for_bc[bc_id]    = dofs_for_bc
            Q_weights[bc_id]        = [1 for _ in dofs_for_bc]
            bc_eqn_str = f"{float(bc_eqn_str) / (0.01 * model_volumes[model])} * H(t) * H(-(t - 2*0.01))"

        bc_eqn = sp.parse_expr(bc_eqn_str, local_dict={"H": H})
        bc_eqn_args = bc_eqn.free_symbols
        # Find out if it uses x, y, or z throw an error.
        if len(spatial_coords.intersection(bc_eqn_args)) > 0:
            raise ValueError(f"Boundary condition {bc_eqn} is written in terms of a spatial coordinate (x, y, z).")
        if bc_eqn_args != {t} and len(bc_eqn_args) != 0:
            raise ValueError(f"Boundary condition {bc_eqn} uses a variable other than t (time).")

        # Take time derivative if needed, and save.
        if bc_is_point_ic or not need_time_deriv_version:
            bc_dict[bc_id][specie] = parse_piecewise_heaviside_into_string(str(bc_eqn))
        else:
            bc_diff = bc_eqn.diff(t)
            bc_dict[bc_id][specie] = parse_piecewise_heaviside_into_string(str(bc_diff))
            bc_dict_for_c0[bc_id][specie] = bc_eqn

            # Zero out c0 for species that have any values specified for a given BC.
            c0[specie_names.index(specie), points_for_bc[bc_id]] = 0

    # Override c0 for PFR
    if need_time_deriv_version:
        for bc_id, species_dict in bc_dict_for_c0.items():
            for specie, bc_eqn in species_dict.items():
                np.add.at(c0[specie_names.index(specie)], points_for_bc[bc_id], np.array(Q_weights[bc_id]) * float(bc_eqn.evalf(subs={'t': t0})))

    bcs_names_used = sorted(bcs_names_used)  # Convert to list to keep order consistent

    # Generate one numpy array for each bc for the points called e.g. points_wall, points_inlet, etc.
    for bc_name in bcs_names_used:
        var_name = "points_" + bc_name
        bc_file_lines.append(f"{var_name} = array({points_for_bc[get_bc_id(bc_name)]})\n")
    bc_file_lines.append("\n")

    # Generate a numpy array for each bc for the flow_weights called e.g. Q_weight_wall
    for bc_name in bcs_names_used:
        var_name = "Q_weights_" + bc_name
        bc_file_lines.append(f"{var_name} = array({Q_weights[get_bc_id(bc_name)]})\n")
    bc_file_lines.append("\n")
    bc_file_lines.append("\n")

    # Generate a single function for each bc named wall_a, wall_b, inlet_c, etc.
    for bc_name in bcs_names_used:
        for specie_name, bc_eqn_str in bc_dict[get_bc_id(bc_name)].items():
            bc_file_lines.append(BC_TEMPLATE.format(f"{bc_name}_{specie_name}", str(bc_eqn_str)))
            bc_file_lines.append("\n\n")

    # Hand unroll the loop to apply the BCs
    bc_file_lines.append("@njit(inline='always')  # Do not cache, _ddt will be a large matrix\n")
    bc_file_lines.append("def boundary_conditions(t: float, _ddt: ndarray) -> None:\n")
    if len(bcs_names_used) == 0:
        bc_file_lines.append('    pass  # No boundary conditions used')
    else:
        for bc_name in bcs_names_used:
            for specie_name in bc_dict[get_bc_id(bc_name)]:
                bc_file_lines.append(f"    _ddt[{specie_names.index(specie_name)}, {'points_' + bc_name}] += {bc_name}_{specie_name}(t) * {'Q_weights_' + bc_name}\n")
            bc_file_lines.append("\n")

    # Write to file
    bc_file_path = config_parser.get_item(['SETUP', 'working_directory'],      str) + '/bc_code_gen.py'
    with open(bc_file_path, "w") as file:
        file.write("".join(bc_file_lines))


def dof_is_pfr_inlet(dof: int, points_per_model: int) -> bool:
    return points_per_model > 1 and dof % points_per_model == 0


def load_initial_conditions(
        config_parser:              ConfigParser,
        c0:                         np.ndarray,
        cmesh:                      CMesh,
        dof_to_element_map:         List[List[Tuple[int, int, float]]],
        point_per_model:            int,
        connected_to_another_inlet: Optional[np.ndarray],
        Q_weight:                   Optional[np.ndarray]
) -> None:
    """
    Parse the string and load its value into the c0 array at the appropriate indices.

    Each variable can have multiple boundary conditions specified. Three categories of BCs are available:
    1. Spatially varying (or uniform) value over the whole domain.                  BC of the form: f(x,y,z)
    2. Spatially varying (or uniform) value over a subset of the domain.            BC of the form: g(x,y,z) @ position predicate
    3. A specific amount (NOT CONCENTRATION) is added at a small position in space. BC of the form: amount * point(x_p,y_p,z_p)

    For each specie, multiple of each of the above categories can be specified. The categories are applied in the order
    listed above. So if a values specified by category 3 intersects with one from category 2, the category 3 value specifies
    the final value. In this vay, category 1 can be thought of as the default.

    If multiple values are specified in a category, they are applied in the order they are found in the config file.
    Except for category 1. There should be at most only one IC per specie of category 1.

    Any degree of freedom that has not had a value specified for it will default to a value of 0.

    A 0th order mapping is used for values of elements to values on DOF. The weighed average (by volume of element) of the
    value in each DOF's elements is used to calculate the value of the DOF.

    Parameters
    ----------
    config_parser:              OpenCCM ConfigParser for getting settings.
    c0:                         The numpy array to hold the initial condition.
    cmesh:                      The CMesh from which the current system was derived.
    dof_to_element_map:
    point_per_model:
    connected_to_another_inlet: TODO

    Returns
    -------
    * Nothing is returned, c0 is modified in place.
    """
    t0           = config_parser.get_list(['SIMULATION', 't_span'],         float)[0]
    specie_names = config_parser.get_list(['SIMULATION', 'specie_names'],   str)
    assert len(set(specie_names)) == len(specie_names)  # Ensure no duplicates

    ic_funcs: Dict[str, List[List[str], List[str], List[str]]] = {specie_name: [[], [], []] for specie_name in specie_names}

    bc_string = config_parser.get_item(['SIMULATION', 'boundary_conditions'], str)
    ic_string = config_parser.get_item(['SIMULATION', 'initial_conditions'],  str)
    for ic_line in ic_string.splitlines():
        specie, ic_funcs_str = [item.strip() for item in ic_line.split('->')]
        if specie not in specie_names:
            raise ValueError(f'Unknown specie: {specie} when specifying initial conditions')

        if "point" in ic_funcs_str:
            ic_funcs[specie][2].append(ic_funcs_str)
        elif "@" in ic_funcs_str:
            ic_funcs[specie][1].append(ic_funcs_str)
        else:
            ic_funcs[specie][0].append(ic_funcs_str)

    # Set of DOFs which don't map to an element, and therefore have to be interpolated based on neighbouring DOFs.
    dofs_to_interpolate = {dof for dof, mapping in enumerate(dof_to_element_map) if len(mapping) == 0 and not dof_is_pfr_inlet(dof, point_per_model)}
    if len(dofs_to_interpolate) == len(dof_to_element_map):
        raise AssertionError(f"No DOF maps to an mesh element.")

    buffer = np.empty(len(cmesh.element_sizes))
    for specie, (full_domain_strs, restricted_strs, point_mass_strs) in ic_funcs.items():
        if len(full_domain_strs) + len(restricted_strs) + len(point_mass_strs) == 0:
            raise ValueError(f"Initial conditions were not specified for specie: {specie}")

        # 1. Handle full domain ICs
        if len(full_domain_strs) == 0:
            buffer[:] = 0
        elif len(full_domain_strs) == 1:
            full_domain_eqn = sp.lambdify(SYMPY_EQN_ARGS, full_domain_strs[0])
            for element, (x_c, y_c, *z_c) in enumerate(cmesh.element_centroids):
                buffer[element] = full_domain_eqn(x_c, y_c, z_c, t0)
        else:
            raise ValueError(f"Only one default IC value can be specified per specie."
                             f"Specie {specie} had {full_domain_strs} specified.")

        # 2. Handle spatial values
        for restricted_str in restricted_strs:
            eqn_str, predicate_str = restricted_str.split('@')
            restricted_eqn, predicate_eqn = sp.lambdify(SYMPY_EQN_ARGS, eqn_str), sp.lambdify(SYMPY_EQN_ARGS, predicate_str)
            for element, (x_c, y_c, *z_c) in enumerate(cmesh.element_centroids):
                if predicate_eqn(x_c, y_c, z_c, t0):
                    buffer[element] = restricted_eqn(x_c, y_c, z_c, t0)

        # 3. Handle point mass by converting them to BCs which will be handled as source terms
        for point_mass_str in point_mass_strs:
            mass_str, point_str = point_mass_str.replace(' ', '').split('@')
            if mass_str == '':
                mass_str = '1.0'
            bc_string += f"{specie}: {point_str} -> {mass_str}\n"

        # 4. Interpolate back from mesh elements to degrees of freedom.
        i_specie = specie_names.index(specie)
        for dof, mapping in enumerate(dof_to_element_map):
            if dof_is_pfr_inlet(dof, point_per_model):
                continue  # Don't map anything to inlet DOFs for PFRs, handle them separately at the end
            elif dof not in dofs_to_interpolate:
                c0[i_specie, dof] = sum(buffer[element] for element, _, _ in mapping) / len(mapping)

    # If any DOFs are not mapped to an element, interpolate them based on nearby DOFs
    for dof in dofs_to_interpolate:
        # 1. Find closest dof before
        dof_before = -1
        for i in range(dof-1, -1, -1):
            if not dof_is_pfr_inlet(i, point_per_model) and i not in dofs_to_interpolate:
                dof_before = i
                break
        # 2. Find closest dof after
        dof_after = -1
        for i in range(dof+1, len(dof_to_element_map)):
            if not dof_is_pfr_inlet(i, point_per_model) and i not in dofs_to_interpolate:
                dof_after = i
                break

        # 3. If either of the DOFs could not be found set it equal to the other
        dof_before = dof_before if dof_before != -1 else dof_after
        dof_after  = dof_after  if dof_after  != -1 else dof_before

        # 4. Interpolate value of the two found DOFs
        c0[:, dof] = (c0[:, dof_before] + c0[:, dof_after]) / 2

    # Handle PFR inlet nodes, ensuring that algebraic equation is satisfied
    if connected_to_another_inlet is not None:
        for (inlet_node, _, _) in connected_to_another_inlet:
            c0[:, inlet_node] = 0
        for (inlet_node, connection, outlet_node) in connected_to_another_inlet:
            c0[:, inlet_node] += Q_weight[connection] * c0[:, outlet_node]

    config_parser['SIMULATION']['boundary_conditions'] = bc_string


def parse_piecewise_heaviside_into_string(str_to_parse: str) -> str:
    """
    Sympy needs a PieceWise function in order to parse the input string and take its derivative

    Each Heavisde gets converted to:

        Piecewise(
            (0.0,                   t < 0),
            (1.0,                   t > 1.0),
            (0.5 - 0.5*cos(pi*t),   True)
        )

    When the time derivative is taken it gets converted to:

        Piecewise(
            (0,                 (t > 1.0) | (t < 0)),
            (pi/2*sin(pi*t),    True)
        )

    Parameters
    ----------
    * str_to_parse: String version of the smoothed Heaviside function.

    Returns
    -------
    * String version of the PieceWise version of the smoothed Heavisde function.
    """
    str_to_parse = str_to_parse.replace(" ", "")
    assert len(str_to_parse) > 0

    if 'Piecewise' not in str_to_parse:
        return str_to_parse

    new_str_fragments = []

    while len(str_to_parse) > 0:  # Parse until the whole string was consumed
        if 'Piecewise' not in str_to_parse:
            new_str_fragments.append(str_to_parse)
            break

        i_func = str_to_parse.index('Piecewise')
        i_split = i_func + len('Piecewise')
        str_left, str_right = str_to_parse[:i_func], str_to_parse[i_split:]
        new_str_fragments.append(str_left)

        i = _get_end_of_first_term(str_right)
        piecewise, str_to_parse = str_right[1:i], str_right[i+1:]

        pieces = []
        while len(piecewise) > 0:
            # Grab the first term based on parenthesis
            i = _get_end_of_first_term(piecewise)
            term, piecewise = piecewise[1:i], piecewise[i+1:]
            if len(piecewise) > 0 and piecewise[0] != ',':
                raise ValueError("Malformed string")
            piecewise = piecewise[1:]

            # Split term into expression and condition
            comma_idxs = [idx for idx, ch in enumerate(term) if ch == ',']
            assert len(comma_idxs) >= 1
            for idx in comma_idxs:
                test_left, test_right = term[:idx], term[idx+1:]
                if (test_left.count('(') == test_left.count(')')) and (test_right.count('(') == test_right.count(')')):
                    break  # Found the comma which represents the split between the two terms.
            else:
                raise ValueError("Malformed string")

            expression, condition = term[:idx], term[idx+1:]
            condition = '(' + condition + ')'
            if 'Piecewise' in expression:  # Recursive call to handle nested Piecewises.
                pieces.append([parse_piecewise_heaviside_into_string(expression), condition])
            else:
                pieces.append(['(' + expression + ')', condition ])

        count_true = 0
        conditions_for_true = []
        for i, (expr, condition) in enumerate(pieces):
            if condition == '(True)':
                count_true += 1
                idx_True = i
            else:
                conditions_for_true.append(condition)
        assert count_true == 1
        pieces[idx_True][1] = "(not (" + " | ".join(conditions_for_true) + "))"

        new_str_fragments.append('(' + ' + '.join(expr + '*' + condition for expr, condition in pieces) + ')')

    return ''.join(new_str_fragments)


def _get_end_of_first_term(str_to_parse: str) -> int:
    """
    Given a well-formed equation in a set of parentheses, return the index into str_to_parse for the closing parenthesis
    that matches the first opening parenthesis in the string.

    Args:
        str_to_parse: String representing a math equation with multiple parentheses

    Returns:
        ~: index of the closing parenthesis
    """
    assert len(str_to_parse) >= 2  # Minimum valid string, i.e. "()"
    assert str_to_parse.count('(') == str_to_parse.count(')')
    assert str_to_parse[0] == '('

    paran_stack = [str_to_parse[0]]

    # Must search right-to-left since there may be multiple independent terms within the string.
    for i in range(1, len(str_to_parse)):
        if str_to_parse[i] == '(':
            paran_stack.append('(')
        elif str_to_parse[i] == ')':
            paran_stack.pop()
            if len(paran_stack) == 0:
                return i

    raise ValueError('Could not find closing parenthesis, equation malformed.')
